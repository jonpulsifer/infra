# NixOS Configuration

This directory contains NixOS configurations for a homelab infrastructure using Nix flakes. The setup manages multiple physical hosts, Kubernetes clusters, Raspberry Pis, and various installation images.

## üèóÔ∏è Architecture

The configuration is organized into modular components:

```
nix/
‚îú‚îÄ‚îÄ hardware/          # Hardware-specific configurations
‚îú‚îÄ‚îÄ hosts/             # Per-host configurations
‚îú‚îÄ‚îÄ profiles/          # Reusable system profiles
‚îú‚îÄ‚îÄ services/          # Service modules (k8s, jellyfin, etc.)
‚îú‚îÄ‚îÄ system/            # Core system configurations
‚îî‚îÄ‚îÄ overlays/          # Package overlays
```

## üñ•Ô∏è Managed Systems

### Kubernetes Clusters

**Folly Cluster** (on-site):
- `nuc` - Intel NUC (control-plane)
- `optiplex` - Dell OptiPlex
- `riptide` - Worker node
- `800g2` - HP EliteDesk 800 G2

**Offsite Cluster**:
- `oldschool` - Offsite control-plane
- `retrofit` - Offsite worker

### Raspberry Pi Systems

- `cloudpi4` - Cloud services Pi
- `homepi4` - Home automation Pi
- `screenpi4` - Display/kiosk Pi

### Installation Images

- `iso` - x86_64 NixOS installation ISO
- `wsl` - Windows Subsystem for Linux tarball
- `gce` - Google Compute Engine image

## üöÄ Quick Start

### Development Environment

Enter the development shell with all required tools:

```bash
nix develop
```

This provides: `kubectl`, `helm`, `terraform`, `vault`, `sops`, `fluxcd`, `cilium-cli`, and more.

### Building Systems

Build a specific system configuration:

```bash
# Build a host system
nix build .#nixosConfigurations.nuc.config.system.build.toplevel

# Build installation media
nix build .#iso         # x86_64 NixOS ISO
nix build .#wsl         # WSL tarball
nix build .#gce         # Google Compute Engine image

# Build Raspberry Pi images
nix build .#cloudpi4    # SD card image
```

### Deploying Updates

After making changes, rebuild and deploy:

```bash
# On the target system (immediate activation)
sudo nixos-rebuild switch --flake .#<hostname>

# Or build remotely and copy (immediate activation)
nixos-rebuild switch --flake .#<hostname> --target-host <hostname> --use-remote-sudo
```

#### Remote Rebuilding with Boot

For safer deployments, especially on remote systems, use `boot` instead of `switch`. This prepares the configuration for the next reboot rather than immediately activating it:

```bash
# Build remotely and prepare for next boot (safer)
nixos-rebuild boot --use-remote-sudo --target-host <hostname> --flake .#<hostname>

# Example: Deploy to oldboy VM via Tailscale
nixos-rebuild boot --use-remote-sudo --target-host nixos.pirate-musical.ts.net --flake .#oldboy
```

**Why use remote rebuilding?**

- **Safety**: `boot` action lets you test the configuration on reboot rather than immediately applying changes
- **Remote systems**: Deploy to systems you can't physically access (cloud VMs, remote servers)
- **Testing**: Verify configurations work before committing to them
- **Rollback**: Easier to rollback if something goes wrong on next boot
- **Network efficiency**: Build locally and transfer only the closure, rather than building on resource-constrained remote systems

**Common systems to rebuild remotely:**

- **Cloud VMs** (e.g., `oldboy` on GCE) - Access via Tailscale or public IP
- **Offsite hosts** (e.g., `oldschool`, `retrofit`) - Remote Kubernetes nodes
- **Headless systems** - Systems without direct console access

## üì¶ Profiles

Reusable configuration profiles in `profiles/`:

- **`rpi.nix`** - Raspberry Pi 4 hardware profile
- **`wsl.nix`** - WSL-specific configuration
- **`iso.nix`** - Live ISO environment
- **`gce.nix`** - Google Compute Engine optimizations

## üîß Services

Custom service modules in `services/`:

- **`k8s/`** - Kubernetes cluster configuration
- **`common.nix`** - Base server configuration with SSH, Tailscale, monitoring
- **`jellyfin.nix`** - Media server
- **`github-runner.nix`** - Self-hosted GitHub Actions runners
- **`kiosk.nix`** - Kiosk mode display
- **`nas.nix`** - Network attached storage
- **`nix-serve.nix`** - Binary cache server
- **`yarr.nix`** - RSS reader

## üåê System Modules

Core system configurations in `system/`:

- **`nixos.nix`** - Base NixOS settings (flakes, caching, auto-upgrade)
- **`user.nix`** - User account management
- **`ssh.nix`** - SSH server configuration
- **`tailscale.nix`** - Tailscale VPN setup
- **`ddnsd.nix`** - Dynamic DNS daemon
- **`fpc.nix`** - Custom FPC configuration

## üîë Inputs & Dependencies

The flake uses several external inputs:

- **`nixpkgs`** - NixOS 25.05 package set
- **`nixos-hardware`** - Hardware-specific configurations
- **`nixos-wsl`** - WSL integration
- **`home-manager`** - User environment management
- **`dotfiles`** - Personal dotfiles repository
- **`ddnsd`** - Custom dynamic DNS daemon
- **`hosts`** - StevenBlack's unified hosts file

SSH keys are automatically imported from GitHub:
- `jonpulsifer.keys` - Main user keys
- `wannabehero.keys` - Additional authorized keys

## üõ†Ô∏è Common Tasks

### Adding a New Host

1. Create a new file in `hosts/<hostname>.nix`:

```nix
{ config, name, ... }:
{
  imports = [
    ../hardware/x86
    ../services/common.nix
  ];
  
  networking.hostName = name;
  # Add host-specific configuration
}
```

2. Add to `flake.nix` outputs:

```nix
nixosConfigurations = builtins.mapAttrs mkSystem {
  # ... existing hosts
  newhostname = { };
};
```

### Creating a New Service

1. Create `services/<service>.nix`:

```nix
{ config, lib, pkgs, ... }:
{
  options.services.<service> = {
    enable = lib.mkEnableOption "<service>";
  };

  config = lib.mkIf config.services.<service>.enable {
    # Service configuration
  };
}
```

2. Import in host configuration:

```nix
imports = [ ../services/<service>.nix ];
services.<service>.enable = true;
```

### Updating Dependencies

Update flake inputs:

```bash
# Update all inputs
nix flake update

# Update specific input
nix flake lock --update-input nixpkgs
```

## üéØ Design Principles

1. **Declarative** - All system state defined in configuration
2. **Modular** - Reusable components shared across hosts
3. **Reproducible** - Flake lock ensures consistent builds
4. **Secure** - Immutable users, automatic security updates
5. **Observable** - Prometheus exporters on all nodes

## üìù Configuration Features

- **Automatic garbage collection** - Weekly cleanup of old generations
- **Binary caching** - Custom cachix cache for faster builds
- **Tailscale integration** - Secure mesh networking
- **SSH hardening** - Key-based auth, fail2ban protection
- **Monitoring** - Node exporters for Prometheus
- **Dynamic DNS** - Automatic DNS updates via ddnsd

## üîç Troubleshooting

### Build failures

```bash
# Check flake evaluation
nix flake check

# Build with verbose output
nix build --verbose .#nixosConfigurations.<host>.config.system.build.toplevel
```

### Disk space issues

```bash
# Manual garbage collection
nix-collect-garbage -d

# Remove old boot entries
sudo nix-collect-garbage -d
sudo /run/current-system/bin/switch-to-configuration boot
```

### WSL VHD optimization

The WSL virtual hard disk can grow large over time. After cleaning up space in WSL, compact the VHD from Windows PowerShell (run as Administrator):

```powershell
# Optimize/compact the NixOS WSL VHD
Optimize-VHD ((Get-ChildItem -Path HKCU:\Software\Microsoft\Windows\CurrentVersion\Lxss | Where-Object { $_.GetValue("DistributionName") -eq 'nixos' }).GetValue("BasePath") + "\ext4.vhdx")
```

This recovers disk space after running garbage collection inside WSL.

### Rolling back

```bash
# List generations
sudo nix-env --list-generations --profile /nix/var/nix/profiles/system

# Rollback to previous generation
sudo nixos-rebuild switch --rollback
```

## üìö Resources

- [NixOS Manual](https://nixos.org/manual/nixos/stable/)
- [Nix Flakes](https://nixos.wiki/wiki/Flakes)
- [NixOS Search](https://search.nixos.org/)
- [Home Manager Manual](https://nix-community.github.io/home-manager/)

## ü§ù Contributing

When making changes:

1. Test locally with `nix flake check`
2. Format code with `nix fmt`
3. Build affected systems to verify
4. Document any new options or services

